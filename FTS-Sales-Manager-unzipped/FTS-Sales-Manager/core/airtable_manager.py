# -*- coding: utf-8 -*-
"""
core/airtable_manager.py - Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ø¥Ø¯Ø§Ø±Ø© Airtable

ÙŠØ¬Ù…Ø¹ ÙˆØ¸Ø§Ø¦Ù:
- airtable_manager.py (Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©)
- airtable_model.py (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¨Ø³ÙŠØ· ÙˆØ§Ù„ÙƒØ§Ø´)
- airtable_integration_helper.py (Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©)

Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© Ø­Ù‚Ù„ Assigned To
"""

import os
import json
import time
import logging
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError
from typing import Dict, List, Any, Optional, Tuple, Callable, Union
from datetime import datetime, timedelta
import requests
import re

logger = logging.getLogger(__name__)


class AirtableManager:
    """
    Ù…Ø¯ÙŠØ± Ù…ÙˆØ­Ø¯ Ù„Ø¬Ù…ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ§Øª Airtable
    ÙŠØ¬Ù…Ø¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
    Ù…Ø¹ Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© Ø­Ù‚Ù„ Assigned To
    """

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ø´ ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡
    CACHE_DURATION = timedelta(minutes=30)
    REQUEST_TIMEOUT = 30
    MAX_RETRIES = 3
    RETRY_DELAY = 1.5
    MAX_WORKERS = 3

    def __init__(self,
                 config_manager=None,
                 db_manager=None,
                 table_name: str = "",
                 view_name: str = None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Airtable Ø§Ù„Ù…ÙˆØ­Ø¯

        :param config_manager: Ù…Ø¯ÙŠØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        :param db_manager: Ù…Ø¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        :param table_name: Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„
        :param view_name: Ø§Ø³Ù… Ø§Ù„Ø¹Ø±Ø¶ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        """
        self.config = config_manager
        self.db = db_manager
        self.table_name = table_name
        self.view_name = view_name

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API
        self._setup_api_config()

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ø´
        self.last_fetch = None
        self.cached_data = []
        self.cache_timestamps = {}
        self._cache_lock = threading.RLock()

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        self.errors = {}
        self._loading = False

        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
        self.cached_related_data = {
            'add_on_prices': [],
            'management_options': [],
            'trip_names': [],
            'users': []
        }

        logger.info(f"ØªÙ… ØªÙ‡ÙŠØ¦Ø© AirtableManager Ù„Ù„Ø¬Ø¯ÙˆÙ„: {table_name}")

    def _setup_api_config(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª API"""
        if self.config:
            self.api_key = self.config.get("airtable_api_key", "")
            self.base_id = self.config.get("airtable_base_id", "")
        else:
            self.api_key = os.getenv('AIRTABLE_API_KEY', "")
            self.base_id = os.getenv('AIRTABLE_BASE_ID', "")

        if not all([self.api_key, self.base_id]):
            logger.error("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Airtable ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø© (API Key Ø£Ùˆ Base ID)")
            return

        # Ø¨Ù†Ø§Ø¡ URL ÙˆØ§Ù„Ù€ headers
        if self.table_name:
            self.endpoint = f"https://api.airtable.com/v0/{self.base_id}/{self.table_name}"

        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json; charset=utf-8"
        }

    def set_table(self, table_name: str, view_name: str = None):
        """ØªØºÙŠÙŠØ± Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ù„Ø¹Ø±Ø¶"""
        self.table_name = table_name
        self.view_name = view_name
        if self.base_id:
            self.endpoint = f"https://api.airtable.com/v0/{self.base_id}/{table_name}"
        logger.info(f"ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¥Ù„Ù‰: {table_name} (Ø§Ù„Ø¹Ø±Ø¶: {view_name or 'Ø§Ù„ÙƒÙ„'})")

    def set_view(self, view_name: str):
        """ØªØºÙŠÙŠØ± Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        self.view_name = view_name
        logger.info(f"ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ø¹Ø±Ø¶ Ø¥Ù„Ù‰: {view_name}")

    # ========================================
    # ğŸ”§ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (CRUD)
    # ========================================

    def fetch_records(self,
                     use_cache: bool = True,
                     force_refresh: bool = False,
                     filter_formula: str = None,
                     view: str = None) -> List[Dict[str, Any]]:
        """
        Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ÙƒØ§Ø´ ÙˆØ§Ù„ÙÙ„ØªØ±Ø©

        :param use_cache: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ§Ø´
        :param force_refresh: Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«
        :param filter_formula: ØµÙŠØºØ© Ø§Ù„ÙÙ„ØªØ±
        :param view: Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        :return: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³Ø¬Ù„Ø§Øª
        """
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
        if use_cache and not force_refresh and self._is_cache_valid():
            logger.debug(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ§Ø´ Ù„Ù„Ø¬Ø¯ÙˆÙ„: {self.table_name}")
            return self.cached_data

        logger.info(f"Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ù† Airtable Ù„Ù„Ø¬Ø¯ÙˆÙ„: {self.table_name}")

        all_records = []
        url = self.endpoint
        params = {"pageSize": 100}

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        if view or self.view_name:
            params["view"] = view or self.view_name
        if filter_formula:
            params["filterByFormula"] = filter_formula

        while True:
            try:
                response = requests.get(
                    url,
                    headers=self.headers,
                    params=params,
                    timeout=self.REQUEST_TIMEOUT
                )
                response.raise_for_status()

                payload = response.json()
                records = payload.get("records", [])
                all_records.extend(records)

                logger.debug(f"Ø§Ø³ØªÙ„Ø§Ù… {len(records)} Ø³Ø¬Ù„ Ù…Ù† {self.table_name}")

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙØ­Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
                offset = payload.get("offset")
                if offset:
                    params["offset"] = offset
                    time.sleep(0.2)  # ØªØ¬Ù†Ø¨ rate limiting
                else:
                    break

            except requests.RequestException as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ù† {self.table_name}: {e}")
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù‚Ø¯ÙŠÙ…
                if self.cached_data:
                    logger.warning("Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø¨Ø³Ø¨Ø¨ ÙØ´Ù„ Ø§Ù„Ø·Ù„Ø¨")
                    return self.cached_data
                raise

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒØ§Ø´
        with self._cache_lock:
            self.cached_data = all_records
            self.last_fetch = datetime.now()
            self.cache_timestamps[self.table_name] = datetime.now()

        # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        if self.db:
            self._save_to_local_db(all_records)

        logger.info(f"ØªÙ… Ø¬Ù„Ø¨ {len(all_records)} Ø³Ø¬Ù„ Ù…Ù† {self.table_name}")
        return all_records

    def fetch_record(self, record_id: str) -> Optional[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø³Ø¬Ù„ ÙˆØ§Ø­Ø¯ Ø¨ÙˆØ§Ø³Ø·Ø© ID"""
        url = f"{self.endpoint}/{record_id}"

        for attempt in range(self.MAX_RETRIES):
            try:
                response = requests.get(
                    url,
                    headers=self.headers,
                    timeout=self.REQUEST_TIMEOUT
                )
                response.raise_for_status()

                record = response.json()
                logger.info(f"ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„ {record_id} Ù…Ù† {self.table_name}")
                return record

            except requests.RequestException as e:
                if attempt < self.MAX_RETRIES - 1:
                    logger.warning(f"Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1} ÙØ´Ù„Øª Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„ {record_id}: {e}")
                    time.sleep(self.RETRY_DELAY * (attempt + 1))
                else:
                    logger.error(f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„ {record_id} Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹: {e}")
                    return None

    def create_record(self, fields: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© ØµØ­ÙŠØ­Ø© Ù„Ø­Ù‚Ù„ Assigned To"""
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
        processed_fields = self._process_fields_for_create(fields)
        payload = {"fields": processed_fields}

        for attempt in range(self.MAX_RETRIES):
            try:
                logger.debug(f"Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {self.table_name}")
                logger.debug(f"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø©: {json.dumps(payload, indent=2, ensure_ascii=False)}")

                # ğŸ” logging Ø®Ø§Øµ Ù„Ø­Ù‚Ù„ Assigned To
                if 'Assigned To' in processed_fields:
                    assigned_value = processed_fields['Assigned To']
                    logger.info(f"ğŸ¯ Assigned To ÙÙŠ Ø§Ù„Ù€ payload: {type(assigned_value)} = {assigned_value}")

                response = requests.post(
                    self.endpoint,
                    headers=self.headers,
                    json=payload,
                    timeout=self.REQUEST_TIMEOUT
                )

                if response.status_code == 422:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø¬Ù„ (422): {response.text}")
                    if "Assigned To" in response.text:
                        logger.error("âŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø­Ù‚Ù„ Assigned To")
                        # logging Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªØ´Ø®ÙŠØµ
                        if 'Assigned To' in processed_fields:
                            assigned_value = processed_fields['Assigned To']
                            logger.error(f"Ù‚ÙŠÙ…Ø© Assigned To Ø§Ù„Ù…Ø±Ø³Ù„Ø©: {assigned_value}")
                            logger.error(f"Ù†ÙˆØ¹ Ø§Ù„Ù‚ÙŠÙ…Ø©: {type(assigned_value)}")
                            logger.error(f"Ù…Ø­ØªÙˆÙ‰ JSON: {json.dumps(assigned_value, ensure_ascii=False)}")
                    return None

                response.raise_for_status()

                # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙƒØ§Ø´ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡
                self._invalidate_cache()

                created = response.json()
                rec_id = created.get("id")
                logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯: {rec_id} ÙÙŠ {self.table_name}")
                return created

            except requests.RequestException as e:
                if attempt < self.MAX_RETRIES - 1:
                    logger.warning(f"Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ {attempt + 1} ÙØ´Ù„Øª: {e}")
                    time.sleep(self.RETRY_DELAY * (attempt + 1))
                else:
                    logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø³Ø¬Ù„ Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹: {e}")
                    if hasattr(e, 'response') and e.response:
                        logger.error(f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {e.response.text}")
                    return None

    def update_record(self, record_id: str, fields: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ù…ÙˆØ¬ÙˆØ¯"""
        url = f"{self.endpoint}/{record_id}"

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„
        processed_fields = self._process_fields_for_update(fields)
        payload = {"fields": processed_fields}

        for attempt in range(self.MAX_RETRIES):
            try:
                logger.debug(f"ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ {record_id} (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1})")

                response = requests.patch(
                    url,
                    headers=self.headers,
                    json=payload,
                    timeout=self.REQUEST_TIMEOUT
                )
                response.raise_for_status()

                # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙƒØ§Ø´
                self._invalidate_cache()

                updated = response.json()
                logger.info(f"ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ {record_id} ÙÙŠ {self.table_name}")
                return updated

            except requests.RequestException as e:
                if attempt < self.MAX_RETRIES - 1:
                    logger.warning(f"Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ« {attempt + 1} ÙØ´Ù„Øª: {e}")
                    time.sleep(self.RETRY_DELAY * (attempt + 1))
                else:
                    logger.error(f"ÙØ´Ù„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ {record_id}: {e}")
                    return None

    def delete_record(self, record_id: str) -> bool:
        """Ø­Ø°Ù Ø³Ø¬Ù„"""
        url = f"{self.endpoint}/{record_id}"

        for attempt in range(self.MAX_RETRIES):
            try:
                response = requests.delete(
                    url,
                    headers=self.headers,
                    timeout=self.REQUEST_TIMEOUT
                )
                response.raise_for_status()

                # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙƒØ§Ø´
                self._invalidate_cache()

                logger.info(f"ØªÙ… Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„ {record_id} Ù…Ù† {self.table_name}")
                return True

            except requests.RequestException as e:
                if attempt < self.MAX_RETRIES - 1:
                    logger.warning(f"Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ø°Ù {attempt + 1} ÙØ´Ù„Øª: {e}")
                    time.sleep(self.RETRY_DELAY * (attempt + 1))
                else:
                    logger.error(f"ÙØ´Ù„ Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„ {record_id}: {e}")
                    return False

    # ========================================
    # ğŸ“„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Pagination & Search)
    # ========================================

    def get_records_paginated(self, limit=50, offset=None):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ø¹ pagination"""
        url = self.endpoint
        params = {"pageSize": min(limit, 100)}

        if offset:
            params["offset"] = offset
        if self.view_name:
            params["view"] = self.view_name

        try:
            response = requests.get(
                url,
                headers=self.headers,
                params=params,
                timeout=self.REQUEST_TIMEOUT
            )
            response.raise_for_status()

            data = response.json()
            records = data.get("records", [])
            next_offset = data.get("offset", None)

            logger.info(f"Ø¬Ù„Ø¨ {len(records)} Ø³Ø¬Ù„ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© Ù…Ù† {self.table_name}")
            return records, next_offset

        except requests.RequestException as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø©: {e}")
            return [], None

    def search_records(self, formula: str) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Airtable formula"""
        try:
            params = {"filterByFormula": formula}
            if self.view_name:
                params["view"] = self.view_name

            response = requests.get(
                self.endpoint,
                headers=self.headers,
                params=params,
                timeout=self.REQUEST_TIMEOUT
            )
            response.raise_for_status()

            records = response.json().get('records', [])
            logger.info(f"ÙˆØ¬Ø¯ {len(records)} Ø³Ø¬Ù„ Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ {self.table_name}")
            return records

        except requests.RequestException as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")
            return []

    # ========================================
    # ğŸ“‹ Ø¯ÙˆØ§Ù„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø©
    # ========================================

    def get_all_values(self, field_name: str = "Name", force_refresh: bool = False) -> List[str]:
        """Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù…Ù† Ø­Ù‚Ù„ Ù…Ø¹ÙŠÙ†"""
        records = self.fetch_records(force_refresh=force_refresh)
        values = []

        for record in records:
            fields = record.get('fields', {})
            value = fields.get(field_name)
            if value and value not in values:
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ…Ø©
                clean_value = str(value).strip()
                if clean_value and clean_value not in values:
                    values.append(clean_value)

        return sorted(values)

    def insert_if_not_exists(self, value: str, field_name: str = "Name") -> bool:
        """Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©"""
        if not value or not value.strip():
            logger.warning(f"Ù‚ÙŠÙ…Ø© ÙØ§Ø±ØºØ© Ù„Ù„Ø­Ù‚Ù„ {field_name}")
            return False

        existing_values = self.get_all_values(field_name)
        clean_value = str(value).strip()

        if clean_value not in existing_values:
            result = self.create_record({field_name: clean_value})
            if result:
                logger.info(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© '{clean_value}' Ø¥Ù„Ù‰ {self.table_name}")
                return True
            return False

        logger.debug(f"Ø§Ù„Ù‚ÙŠÙ…Ø© '{clean_value}' Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ {self.table_name}")
        return False

    # Ø¯ÙˆØ§Ù„ Ù…ØªØ®ØµØµØ© Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    def fetch_agencies(self, field_name: str = "Agency Name") -> List[str]:
        """Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙˆÙƒØ§Ù„Ø§Øª"""
        return self._fetch_dropdown_values(field_name, ["Agency Name", "Name", "Agency"])

    def fetch_guides(self, field_name: str = "Name") -> List[str]:
        """Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø±Ø´Ø¯ÙŠÙ†"""
        return self._fetch_dropdown_values(field_name, ["Guide Name", "Name", "Language"])

    def fetch_destinations(self, field_name: str = "Destination") -> List[str]:
        """Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙˆØ¬Ù‡Ø§Øª"""
        return self._fetch_dropdown_values(field_name, ["Destination", "Name", "City", "Location"])

    def get_dropdown_values(self, field_name: str, default_field: str = "Name") -> List[str]:
        """Ø¯Ø§Ù„Ø© Ø¹Ø§Ù…Ø© Ù„Ø¬Ù„Ø¨ Ù‚ÙŠÙ… Ø£ÙŠ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù†Ø³Ø¯Ù„Ø©"""
        return self._fetch_dropdown_values(field_name, [field_name, default_field])

    def _fetch_dropdown_values(self, primary_field: str, fallback_fields: List[str]) -> List[str]:
        """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¬Ù„Ø¨ Ù‚ÙŠÙ… Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø©"""
        try:
            records = self.fetch_records()
            values = []

            for record in records:
                fields = record.get('fields', {})
                value = None

                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
                for field in fallback_fields:
                    if field in fields and fields[field]:
                        value = fields[field]
                        break

                if value:
                    clean_value = str(value).strip()
                    if clean_value and clean_value not in values:
                        values.append(clean_value)

            values.sort()
            logger.info(f"ØªÙ… Ø¬Ù„Ø¨ {len(values)} Ù‚ÙŠÙ…Ø© Ù…Ù† {primary_field} ÙÙŠ {self.table_name}")
            return values

        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù‚ÙŠÙ… {primary_field}: {e}")
            return []

    # ========================================
    # ğŸ”— Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© (Ù…Ù† integration_helper)
    # ========================================

    def fetch_all_related_data(self, callback=None, error_callback=None):
        """Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©"""
        def fetch_task():
            try:
                # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
                self._fetch_add_on_prices()
                self._fetch_management_options()
                self._fetch_trip_names()
                self._fetch_users()

                logger.info("ØªÙ… Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©")

                if callback:
                    callback(self.cached_related_data)

                return self.cached_related_data

            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©: {e}")
                if error_callback:
                    error_callback(str(e))
                raise

        # ØªØ´ØºÙŠÙ„ ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„
        threading.Thread(target=fetch_task, daemon=True).start()

    def _fetch_add_on_prices(self):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª"""
        original_table = self.table_name
        try:
            self.set_table("Add-on prices")
            records = self.fetch_records(use_cache=False)
            add_ons = []

            for record in records:
                fields = record.get('fields', {})
                add_on_name = fields.get('Add-ons', '')
                if add_on_name:
                    add_ons.append(add_on_name)

            self.cached_related_data['add_on_prices'] = sorted(list(set(add_ons)))
            logger.info(f"ØªÙ… Ø¬Ù„Ø¨ {len(add_ons)} Ø¥Ø¶Ø§ÙØ©")

        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Add-on prices: {e}")
        finally:
            self.set_table(original_table)

    def _fetch_management_options(self):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©"""
        original_table = self.table_name
        try:
            self.set_table("Management Option")
            records = self.fetch_records(use_cache=False)
            options = []

            for record in records:
                fields = record.get('fields', {})
                option_name = fields.get('Main Option', '')
                if option_name:
                    options.append(option_name)

            self.cached_related_data['management_options'] = sorted(list(set(options)))
            logger.info(f"ØªÙ… Ø¬Ù„Ø¨ {len(options)} Ø®ÙŠØ§Ø± Ø¥Ø¯Ø§Ø±Ø©")

        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Management Option: {e}")
        finally:
            self.set_table(original_table)

    def _fetch_trip_names(self):
        """Ø¬Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø±Ø­Ù„Ø§Øª"""
        original_table = self.table_name
        try:
            self.set_table("Trip Name Correction")
            records = self.fetch_records(use_cache=False)
            trip_names = []

            for record in records:
                fields = record.get('fields', {})
                old_name = fields.get('Old Name', '')
                new_name = fields.get('New Name', '')

                trip_name = new_name if new_name else old_name
                if trip_name:
                    trip_names.append(trip_name)

            self.cached_related_data['trip_names'] = sorted(list(set(trip_names)))
            logger.info(f"ØªÙ… Ø¬Ù„Ø¨ {len(trip_names)} Ø§Ø³Ù… Ø±Ø­Ù„Ø©")

        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Trip Name Correction: {e}")
        finally:
            self.set_table(original_table)

    def _fetch_users(self):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
        original_table = self.table_name
        try:
            self.set_table("Users")
            records = self.fetch_records(use_cache=False)
            users = []

            for record in records:
                fields = record.get('fields', {})
                username = fields.get('Username', '')
                collaborator = fields.get('Airtable Collaborator')

                if username:
                    users.append(username)
                elif collaborator and isinstance(collaborator, dict):
                    user_name = collaborator.get('name', '')
                    if user_name:
                        users.append(user_name)

            self.cached_related_data['users'] = sorted(list(set(users)))
            logger.info(f"ØªÙ… Ø¬Ù„Ø¨ {len(users)} Ù…Ø³ØªØ®Ø¯Ù…")

        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Users: {e}")
        finally:
            self.set_table(original_table)

    def get_cached_related_data(self) -> Dict[str, List[str]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø§Ù„Ù…Ø®Ø²Ù†Ø©"""
        return self.cached_related_data

    def refresh_related_data(self, table_name: Optional[str] = None):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©"""
        if table_name:
            if table_name == "Add-on prices":
                self._fetch_add_on_prices()
            elif table_name == "Management Option":
                self._fetch_management_options()
            elif table_name == "Trip Name Correction":
                self._fetch_trip_names()
            elif table_name == "Users":
                self._fetch_users()
        else:
            self.fetch_all_related_data()

    # ========================================
    # ğŸ› ï¸ Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙˆÙƒØ§Ø´
    # ========================================

    def _process_fields_for_create(self, fields: Dict[str, Any]) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ - Ù…Ø­Ø¯Ø«Ø© Ù„Ø­Ù‚Ù„ Assigned To"""
        processed = {}

        for key, value in fields.items():
            if key == 'Assigned To':
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ø­Ù‚Ù„ Assigned To - Ø¥Ø±Ø¬Ø§Ø¹ object
                processed_value = self._process_assigned_to_field(value)
                if processed_value:  # ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù‚ÙŠÙ…Ø© ØµØ§Ù„Ø­Ø©
                    processed[key] = processed_value
                    logger.debug(f"âœ… Assigned To processed: {processed_value}")
            elif value is not None and str(value).strip():
                processed[key] = value

        return processed

    def _process_fields_for_update(self, fields: Dict[str, Any]) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ« - Ù…Ø­Ø¯Ø«Ø© Ù„Ø­Ù‚Ù„ Assigned To"""
        processed = {}

        for key, value in fields.items():
            if key == 'Assigned To':
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ø­Ù‚Ù„ Assigned To
                processed_value = self._process_assigned_to_field(value)
                if processed_value:
                    processed[key] = processed_value
            else:
                processed[key] = value

        return processed

    def _process_assigned_to_field(self, value: Any) -> Optional[Dict[str, str]]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù…Ø­Ø³Ù†Ø© Ù„Ø­Ù‚Ù„ Assigned To - Ø¥Ø±Ø¬Ø§Ø¹ object Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† string"""
        if value is None:
            return None

        # Ø¥Ø°Ø§ ÙƒØ§Ù† dict Ø¨Ø§Ù„ÙØ¹Ù„ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ id Ø£Ùˆ email
        if isinstance(value, dict):
            if 'id' in value:
                user_id = str(value['id']).strip()
                logger.debug(f"Dict with id found: {user_id}")
                return {"id": user_id}
            elif 'email' in value:
                email = str(value['email']).strip()
                logger.debug(f"Dict with email found: {email}")
                return {"email": email}
            else:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù‚ÙŠÙ…Ø© Ù…ÙÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ù€ dict
                for k, v in value.items():
                    if v and str(v).strip():
                        clean_val = str(v).strip()
                        if '@' in clean_val:
                            return {"email": clean_val}
                        elif clean_val.startswith(('usr', 'rec')) or len(clean_val) > 10:
                            return {"id": clean_val}
                return None

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ string Ø£ÙˆÙ„Ø§Ù‹
        str_value = str(value)

        # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ escape characters Ø£Ùˆ quotes Ø²Ø§Ø¦Ø¯Ø©
        cleaned_value = str_value.strip()

        # Ø¥Ø²Ø§Ù„Ø© quotes Ø®Ø§Ø±Ø¬ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
        while cleaned_value.startswith('"') and cleaned_value.endswith('"'):
            cleaned_value = cleaned_value[1:-1]

        while cleaned_value.startswith("'") and cleaned_value.endswith("'"):
            cleaned_value = cleaned_value[1:-1]

        # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ backslashes Ø²Ø§Ø¦Ø¯Ø©
        cleaned_value = cleaned_value.replace('\\"', '"').replace("\\'", "'")

        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù…Ø¹Ø±Ù Airtable User
        final_value = cleaned_value.strip()

        # logging Ù„Ù„ØªØ´Ø®ÙŠØµ
        if str_value != final_value:
            logger.debug(f"ØªÙ†Ø¸ÙŠÙ Assigned To: '{str_value}' â†’ '{final_value}'")

        # âœ… Ø¥Ø±Ø¬Ø§Ø¹ object Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù€ Airtable
        if final_value:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù‚ÙŠÙ…Ø© (ID Ø£Ù… Email)
            if final_value.startswith('usr') or final_value.startswith('rec'):
                # Ù…Ø¹Ø±Ù Airtable User/Record
                logger.debug(f"Ø¥Ø±Ø¬Ø§Ø¹ User ID: {final_value}")
                return {"id": final_value}
            elif '@' in final_value and '.' in final_value:
                # Ø¹Ù†ÙˆØ§Ù† Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
                logger.debug(f"Ø¥Ø±Ø¬Ø§Ø¹ Email: {final_value}")
                return {"email": final_value}
            else:
                # Ø§ÙØªØ±Ø§Ø¶ Ø£Ù†Ù‡ Ù…Ø¹Ø±Ù Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ÙŠØ¨Ø¯Ø£ Ø¨Ù€ usr
                logger.debug(f"Ø¥Ø±Ø¬Ø§Ø¹ ID (Ø§ÙØªØ±Ø§Ø¶ÙŠ): {final_value}")
                return {"id": final_value}

        return None

    def _validate_user_field_format(self, value: Any) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙ†Ø³ÙŠÙ‚ Ø­Ù‚Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if not value:
            return False

        if isinstance(value, dict):
            return 'id' in value or 'email' in value

        if isinstance(value, str):
            value = value.strip()
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¹Ø±Ù Airtable Ø£Ùˆ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
            return (value.startswith(('usr', 'rec')) and len(value) >= 10) or ('@' in value and '.' in value)

        return False

    def _is_cache_valid(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙƒØ§Ø´"""
        if not self.last_fetch or not self.cached_data:
            return False

        age = datetime.now() - self.last_fetch
        return age < self.CACHE_DURATION

    def _invalidate_cache(self):
        """Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙƒØ§Ø´"""
        with self._cache_lock:
            self.last_fetch = None
            self.cached_data = []
            if self.table_name in self.cache_timestamps:
                del self.cache_timestamps[self.table_name]

    def _save_to_local_db(self, records: List[Dict[str, Any]]):
        """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©"""
        try:
            if self.db and hasattr(self.db, 'save_records'):
                self.db.save_records(self.table_name, records)
        except Exception as e:
            logger.warning(f"ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù„ÙŠØ§Ù‹: {e}")

    def get_cache_info(self) -> Dict[str, Any]:
        """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒØ§Ø´"""
        with self._cache_lock:
            return {
                'table': self.table_name,
                'cached_records': len(self.cached_data),
                'last_fetch': self.last_fetch.isoformat() if self.last_fetch else None,
                'cache_age_seconds': (datetime.now() - self.last_fetch).total_seconds() if self.last_fetch else None,
                'is_valid': self._is_cache_valid()
            }

    def clear_cache(self):
        """Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´"""
        self._invalidate_cache()
        logger.info(f"ØªÙ… Ù…Ø³Ø­ ÙƒØ§Ø´ {self.table_name}")

    def is_connected(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„"""
        return bool(self.api_key and self.base_id)

    def get_status(self) -> Dict[str, Any]:
        """Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¯ÙŠØ±"""
        return {
            'connected': self.is_connected(),
            'table_name': self.table_name,
            'view_name': self.view_name,
            'loading': self._loading,
            'cached_records': len(self.cached_data),
            'cache_valid': self._is_cache_valid(),
            'errors': self.errors.copy(),
            'related_data_cached': {
                key: len(values) for key, values in self.cached_related_data.items()
            }
        }

    # ========================================
    # ğŸ”§ Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ´Ø®ÙŠØµ ÙˆØ§Ù„ØªØµØ­ÙŠØ­
    # ========================================

    def debug_assigned_to_processing(self, test_values: List[Any]) -> Dict[str, Any]:
        """Ø¯Ø§Ù„Ø© ØªØ´Ø®ÙŠØµ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù‚Ù„ Assigned To"""
        results = {}

        logger.info("ğŸ” Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù‚Ù„ Assigned To")
        logger.info("=" * 50)

        for i, test_value in enumerate(test_values):
            try:
                logger.info(f"Ø§Ø®ØªØ¨Ø§Ø± {i+1}: {type(test_value)} = {test_value}")

                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ…Ø©
                processed = self._process_assigned_to_field(test_value)

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
                is_valid = self._validate_user_field_format(processed)

                results[f"test_{i+1}"] = {
                    "input": test_value,
                    "input_type": str(type(test_value)),
                    "processed": processed,
                    "processed_type": str(type(processed)),
                    "is_valid": is_valid,
                    "success": processed is not None
                }

                logger.info(f"âœ… Ø§Ù„Ù†ØªÙŠØ¬Ø©: {processed} (ØµØ­ÙŠØ­: {is_valid})")

            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
                results[f"test_{i+1}"] = {
                    "input": test_value,
                    "error": str(e),
                    "success": False
                }

            logger.info("-" * 30)

        logger.info("=" * 50)
        return results

    def test_user_field_creation(self, user_id: str) -> bool:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ø¹ Ø­Ù‚Ù„ Assigned To"""
        try:
            logger.info(f"ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ù…Ø¹ Assigned To: {user_id}")

            # ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
            test_fields = {
                "Customer Name": f"Test User {datetime.now().strftime('%H%M%S')}",
                "Assigned To": user_id,
                "Agency": "Test Agency"
            }

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„
            processed = self._process_fields_for_create(test_fields)

            logger.info(f"Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {json.dumps(processed, ensure_ascii=False, indent=2)}")

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†Ø³ÙŠÙ‚ Assigned To
            if 'Assigned To' in processed:
                assigned_to = processed['Assigned To']
                is_valid = self._validate_user_field_format(assigned_to)
                logger.info(f"ØªÙ†Ø³ÙŠÙ‚ Assigned To ØµØ­ÙŠØ­: {is_valid}")
                return is_valid

            return False

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {e}")
            return False

    def validate_record_fields(self, fields: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø³Ø¬Ù„ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„"""
        errors = []

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        required_fields = ['Customer Name']  # ÙŠÙ…ÙƒÙ† ØªØ®ØµÙŠØµÙ‡Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø¬Ø¯ÙˆÙ„

        for field in required_fields:
            if field not in fields or not fields[field]:
                errors.append(f"Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ '{field}' Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ÙØ§Ø±Øº")

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†Ø³ÙŠÙ‚ Ø­Ù‚Ù„ Assigned To
        if 'Assigned To' in fields:
            assigned_to = fields['Assigned To']
            if not self._validate_user_field_format(assigned_to):
                errors.append(f"ØªÙ†Ø³ÙŠÙ‚ Ø­Ù‚Ù„ 'Assigned To' ØºÙŠØ± ØµØ­ÙŠØ­: {assigned_to}")

        return len(errors) == 0, errors

    def create_record_with_validation(self, fields: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„
        is_valid, errors = self.validate_record_fields(fields)

        if not is_valid:
            logger.error("âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„:")
            for error in errors:
                logger.error(f"  - {error}")
            return None

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø³Ø¬Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØµØ­ÙŠØ­Ø©
        return self.create_record(fields)


# ========================================
# ğŸ­ Ø¯ÙˆØ§Ù„ Factory Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
# ========================================

def create_airtable_manager(config_manager=None, db_manager=None, table_name: str = "") -> AirtableManager:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Airtable Ø¹Ø§Ù…"""
    return AirtableManager(config_manager, db_manager, table_name)

def create_bookings_manager(config_manager=None, db_manager=None, view_name: str = None) -> AirtableManager:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø­Ø¬ÙˆØ²Ø§Øª"""
    return AirtableManager(config_manager, db_manager, "Bookings", view_name)

def create_agencies_manager(config_manager=None, db_manager=None) -> AirtableManager:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙˆÙƒØ§Ù„Ø§Øª"""
    return AirtableManager(config_manager, db_manager, "Agencies")

def create_guides_manager(config_manager=None, db_manager=None) -> AirtableManager:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø±Ø´Ø¯ÙŠÙ†"""
    return AirtableManager(config_manager, db_manager, "Guides")

def create_destinations_manager(config_manager=None, db_manager=None) -> AirtableManager:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙˆØ¬Ù‡Ø§Øª"""
    return AirtableManager(config_manager, db_manager, "Destinations")

def create_users_manager(config_manager=None, db_manager=None) -> AirtableManager:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
    return AirtableManager(config_manager, db_manager, "Users")


# ========================================
# ğŸ”„ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…
# ========================================

class AirtableModel(AirtableManager):
    """ÙƒÙ„Ø§Ø³ Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ… - ÙˆØ±Ø§Ø«Ø© Ù…Ù† AirtableManager"""

    def __init__(self, config_manager, db_manager, table_name: str, view_name: str = None):
        super().__init__(config_manager, db_manager, table_name, view_name)
        logger.info(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ AirtableModel (ØªÙˆØ§ÙÙ‚) Ù„Ù„Ø¬Ø¯ÙˆÙ„: {table_name}")

    # Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙˆØ§ÙÙ‚
    def fetch_all_records(self, view: Optional[str] = None, force_refresh: bool = False) -> List[Dict[str, Any]]:
        """Ø¯Ø§Ù„Ø© ØªÙˆØ§ÙÙ‚ - Ø§Ø³ØªØ®Ø¯Ø§Ù… fetch_records"""
        return self.fetch_records(force_refresh=force_refresh, view=view)

    def get_record_by_id(self, record_id: str) -> Optional[Dict[str, Any]]:
        """Ø¯Ø§Ù„Ø© ØªÙˆØ§ÙÙ‚ - Ø§Ø³ØªØ®Ø¯Ø§Ù… fetch_record"""
        return self.fetch_record(record_id)